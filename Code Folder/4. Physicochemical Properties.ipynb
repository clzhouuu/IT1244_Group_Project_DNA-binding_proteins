{"cells":[{"cell_type":"markdown","metadata":{"id":"nbkhlX8wpSgM"},"source":["# Introduction\n","\n","##### Each protein sequence in the dataset consists of amino acids - each character is a representation of one amino acid\n","\n","![20 amino acids that make up protein](https://i0.wp.com/www.compoundchem.com/wp-content/uploads/2014/09/20-Common-Amino-Acids.png?fit=2480%2C1754&ssl=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4175,"status":"ok","timestamp":1730523636285,"user":{"displayName":"Nguyễn Huy Tùng","userId":"08271397253811785605"},"user_tz":-480},"id":"ms5OSNpQr7H5","outputId":"1e0babc9-84e1-417f-fff1-b91576c6a98c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: Bio in /usr/local/lib/python3.10/dist-packages (1.7.1)\n","Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.10/dist-packages (from Bio) (1.84)\n","Requirement already satisfied: gprofiler-official in /usr/local/lib/python3.10/dist-packages (from Bio) (1.0.0)\n","Requirement already satisfied: mygene in /usr/local/lib/python3.10/dist-packages (from Bio) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from Bio) (2.2.2)\n","Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from Bio) (1.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Bio) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from Bio) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython>=1.80->Bio) (1.26.4)\n","Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from mygene->Bio) (0.3.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2024.2)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (4.3.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (24.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2024.8.30)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.16.0)\n"]}],"source":["!pip install Bio"]},{"cell_type":"markdown","metadata":{"id":"FepyBILBpSgP"},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yuQgJtJZpSgP"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import random as random\n","from Bio import SeqIO\n","from Bio.SeqUtils.ProtParam import ProteinAnalysis"]},{"cell_type":"markdown","metadata":{"id":"rCqRCONKpSgQ"},"source":["# Hydropathy Calculation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OeCN-8bEpSgQ"},"outputs":[],"source":["hydropathy_index = {\n","    'A': 1.8,   # Alanine\n","    'C': 2.5,   # Cysteine\n","    'D': -3.5,  # Aspartic Acid\n","    'E': -3.5,  # Glutamic Acid\n","    'F': 2.8,   # Phenylalanine\n","    'G': -0.4,  # Glycine\n","    'H': -0.2,  # Histidine\n","    'I': 4.5,   # Isoleucine\n","    'K': -3.9,  # Lysine\n","    'L': 3.8,   # Leucine\n","    'M': 1.9,   # Methionine\n","    'N': -3.5,  # Asparagine\n","    'P': -1.6,  # Proline\n","    'Q': -3.5,  # Glutamine\n","    'R': -4.5,  # Arginine\n","    'S': -0.8,  # Serine\n","    'T': -0.7,  # Threonine\n","    'V': 4.2,   # Valine\n","    'W': -0.9,  # Tryptophan\n","    'Y': -1.3,  # Tyrosine\n","}\n","\n","\n","def hydropathy(protein_sequence, amino_acid_list):\n","    hydropathy = 0\n","    for amino_acid in protein_sequence:\n","        if amino_acid not in amino_acid_list:\n","            continue\n","        hydropathy += hydropathy_index[amino_acid]\n","    return hydropathy / len(protein_sequence)"]},{"cell_type":"markdown","metadata":{"id":"4hiPTBElpSgR"},"source":["# Net Charge Calculation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akTo_LVPpSgR"},"outputs":[],"source":["selected_pH = 7.0\n","\n","\n","pKa_values = {\n","        'K': 10.5,  # Lysine\n","        'R': 12.5,  # Arginine\n","        'H': 6.0,   # Histidine\n","        'D': 3.9,   # Aspartic acid\n","        'E': 4.2    # Glutamic acid\n","    }\n","\n","\n","def net_charge(protein_sequence, pH=selected_pH):\n","\n","    charge = 0\n","\n","    for amino_acid in protein_sequence:\n","        if amino_acid in pKa_values:\n","            if amino_acid in ['K', 'R', 'H']:  # Basic amino acids\n","                if pH < pKa_values[amino_acid]:\n","                    charge += 1  # Protonated form (positive charge)\n","            elif amino_acid in ['D', 'E']:  # Acidic amino acids\n","                if pH > pKa_values[amino_acid]:\n","                    charge -= 1  # Deprotonated form (negative charge)\n","\n","    return charge\n"]},{"cell_type":"markdown","metadata":{"id":"-3Mzmfd5pSgR"},"source":["# Set up Feature Distribution\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbu78e2opSgR"},"outputs":[],"source":["def plot_feature_distribution(data, feature, start=None, end=None):\n","\n","    column_list = {1: \"DNA-binding\", 0: \"non DNA-binding\"}\n","\n","    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 8))\n","    axes  = axes.flatten()\n","\n","    for i, column in enumerate(column_list):\n","        used_data = data[data[\"Label\"] == column][feature]\n","        axes[i].boxplot(used_data, patch_artist=True,\n","                        boxprops=dict(facecolor='lightblue',\n","                                      edgecolor='black'))\n","        axes[i].set_xlabel(feature)\n","        axes[i].set_title(column_list[column])\n","        axes[i].set_ylim(start, end)\n","\n","    plt.subplots_adjust(wspace=0.25)\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"NcecKsDQpSgS"},"source":["# Feature Scaling - Set up"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHQ15sX4pSgS"},"outputs":[],"source":["from sklearn.preprocessing import RobustScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmy-2p7TpSgS"},"outputs":[],"source":["def normalize(data):\n","    min_max_scaler = MinMaxScaler()\n","    normalized_data = min_max_scaler.fit_transform(data)\n","    normalized_df = pd.DataFrame(normalized_data, columns=data.columns)\n","    return normalized_df\n","\n","\n","def standardize(data):\n","    scaler = StandardScaler()\n","    standardized_data = scaler.fit_transform(data)\n","    standardized_df = pd.DataFrame(standardized_data, columns=data.columns)\n","    return standardized_df\n","\n","\n","def robust_scaling(data):\n","    scaler = RobustScaler()\n","    robust_scaled_data = scaler.fit_transform(data)\n","    robus_scaled_df = pd.DataFrame(robust_scaled_data, columns=data.columns)\n","    return robus_scaled_df"]},{"cell_type":"markdown","metadata":{"id":"NHbATWUwpSgS"},"source":["# Read data(.fasta file) and convert to .csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ogB9g6ezpSgS"},"outputs":[],"source":["amino_acids_list = ['A', 'R', 'N', 'D', 'C', 'E', 'Q',\n","                    'G', 'H', 'I', 'L', 'K', 'M', 'F',\n","                    'P', 'S', 'T', 'W', 'Y', 'V']"]},{"cell_type":"markdown","metadata":{"id":"4qbSFyJIpSgS"},"source":["##### Data Cleaning - Remove unnecessary amino acids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpM8tMt0pSgS"},"outputs":[],"source":["characters_to_remove = ['X', 'U', \"O\", \"B\"]\n","\n","\n","def remove_character(input_string, chars_to_remove):\n","    for char in chars_to_remove:\n","        input_string = input_string.replace(char, '')\n","    return input_string"]},{"cell_type":"markdown","metadata":{"id":"G31J89PQpSgT"},"source":["##### Read .fasta file and convert to .csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"No9HMxv3pSgT"},"outputs":[],"source":["def set_up_fasta_data(file_path, name):\n","\n","\n","    data = []\n","    records = SeqIO.parse(file_path, \"fasta\")\n","\n","    for record in records:\n","        data.append([record.id, record.seq])\n","\n","    data = pd.DataFrame(data, columns=[\"Label\", \"Sequence\"])\n","    data['Label'] = data['Label'].apply(lambda x: x[-1])\n","    data['Length'] = data['Sequence'].apply(len)\n","\n","    for amino_acid in amino_acids_list:\n","        data['Frequency_' + amino_acid] = data['Sequence'].apply(lambda x:\n","                                            x.count(amino_acid) / len(x))\n","\n","    data['Sequence'] = data['Sequence'].apply(lambda x:\n","                                remove_character(x, characters_to_remove))\n","\n","    # Create new column: Hydropathy\n","    data['Hydropathy'] = data['Sequence'].apply(lambda x:\n","                        hydropathy(x, amino_acids_list))\n","\n","    # Create new column: Net_charge\n","    data['Net_charge'] = data['Sequence'].apply(lambda x: net_charge(x))\n","\n","\n","\n","    ########## ADDING PHYSICOCHEMICAL PROPERTIES ##########\n","\n","    # Define empty lists to store the computed values for each feature column\n","    molecular_weights = []\n","    instability_indexes = []\n","    aromaticities = []\n","    flexibilities = []\n","    isoelectric_points = []\n","    sec_structure_fractions = []\n","\n","    # Iterate through each protein sequence in the 'Sequence' column\n","    for seq in data['Sequence']:\n","        X = ProteinAnalysis(seq)\n","\n","        # Append the computed values for each property to the respective list\n","        molecular_weights.append(X.molecular_weight())\n","        instability_indexes.append(X.instability_index())\n","        aromaticities.append(X.aromaticity())\n","        flexibilities.append(X.flexibility())  # Flexibility is a list\n","        isoelectric_points.append(X.isoelectric_point())\n","        sec_structure_fractions.append(X.secondary_structure_fraction())\n","\n","    # Add these lists as new columns to your DataFrame\n","    data['Molecular Weight'] = molecular_weights\n","    data['Instability Index'] = instability_indexes\n","    data['Aromaticity'] = aromaticities\n","    data['Flexibility(Mean)'] = [sum(flex)/len(flex) if len(flex) > 0\n","                                 else 0 for flex in flexibilities]\n","    data['Isoelectric Point'] = isoelectric_points\n","    data['Secondary Structure Fraction'] = [sum(fraction)/len(fraction)\n","                                for fraction in sec_structure_fractions]\n","\n","\n","\n","    ########## CONVERT TO CSV ##########\n","\n","    data.to_csv(name, index=False)\n","\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2794,"status":"ok","timestamp":1730523639076,"user":{"displayName":"Nguyễn Huy Tùng","userId":"08271397253811785605"},"user_tz":-480},"id":"ra43442eGT-Y","outputId":"93427812-9394-4259-d9c0-a437f2a08953"},"outputs":[{"ename":"ValueError","evalue":"mount failed","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"08p3Ku-HpSgT"},"source":["##### Set up dataframe for train set and test set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7oPrlVjCpSgT"},"outputs":[],"source":["# Read dataset(.fasta file) and convert to csv\n","#dna_train = set_up_fasta_data(\"Data/Train.fasta\", \"Data/DNA_Train.csv\")\n","#dna_test = set_up_fasta_data('Data/Test.fasta', \"Data/DNA_Test.csv\")"]},{"cell_type":"markdown","metadata":{"id":"tBktOGaEpSgT"},"source":["##### Already convert and from now will use the csv file to read data (much faster)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3AAP9W6tpSgT"},"outputs":[],"source":["train_data_path = '/content/drive/MyDrive/IT1244 Group Project/For submission/Model & Data Set/DNA_Train.csv'\n","test_data_path = '/content/drive/MyDrive/IT1244 Group Project/For submission/Model & Data Set/DNA_Test.csv'\n","\n","\n","# Define paths relative to the main folder\n","dna_train = pd.read_csv(train_data_path)\n","dna_test = pd.read_csv(test_data_path)\n","# dna_train = pd.read_csv(\"Data/DNA_Train.csv\")\n","# dna_test = pd.read_csv(\"Data/DNA_Test.csv\")\n","\n","\n","# Convert 'Label' to a categorical variable\n","dna_train['Label'] = pd.Categorical(dna_train['Label'])\n","dna_test['Label'] = pd.Categorical(dna_test['Label'])\n","\n","\n","# Remove missing values from the training data\n","dna_train = dna_train.dropna()\n","dna_test = dna_test.dropna()\n","\n","\n","# Ensure the labels are treated as binary\n","dna_train['Label'] = dna_train['Label'].cat.codes  # 0 for \"0\" and 1 for \"1\"\n","dna_test['Label'] = dna_test['Label'].cat.codes"]},{"cell_type":"markdown","metadata":{"id":"o9RyZt19pSgT"},"source":["# Feature Distribution"]},{"cell_type":"markdown","metadata":{"id":"5m7LrE5zpSgU"},"source":["### Physicochemical Properties"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rRdRpVeMpSgU"},"outputs":[],"source":["plot_feature_distribution(dna_train, 'Hydropathy', -3, 3)\n","\n","plot_feature_distribution(dna_train, 'Net_charge', -500, 500)\n","\n","plot_feature_distribution(dna_train, 'Molecular Weight')\n","\n","plot_feature_distribution(dna_train, 'Instability Index', -50, 180)\n","\n","plot_feature_distribution(dna_train, 'Aromaticity', -0.05, 0.4)\n","\n","plot_feature_distribution(dna_train, 'Flexibility(Mean)', 0.93, 1.06)\n","\n","plot_feature_distribution(dna_train, 'Isoelectric Point')\n","\n","plot_feature_distribution(dna_train, 'Secondary Structure Fraction', 0.1, 0.45)"]},{"cell_type":"markdown","metadata":{"id":"HYxO-AMzpSgU"},"source":["# Set up features, trainX, trainY, testX, testY"]},{"cell_type":"markdown","metadata":{"id":"s8Lg9JGSpSgU"},"source":["### Column names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UZrhQ7P-pSgU"},"outputs":[],"source":["columns = [ # 0\n","            'Length',\n","\n","            # 1 - 20\n","            'Frequency_A', 'Frequency_R', 'Frequency_N', 'Frequency_D',\n","            'Frequency_C', 'Frequency_E', 'Frequency_Q', 'Frequency_G',\n","            'Frequency_H', 'Frequency_I', 'Frequency_L', 'Frequency_K',\n","            'Frequency_M', 'Frequency_F', 'Frequency_P', 'Frequency_S',\n","            'Frequency_T', 'Frequency_W', 'Frequency_Y', 'Frequency_V',\n","\n","            # 21 - 22\n","            'Hydropathy',\n","            'Net_charge',\n","\n","            # 23 - 24\n","            'Molecular Weight',\n","            'Instability Index',\n","\n","            # 25 - 26\n","            'Aromaticity',\n","            'Flexibility(Mean)',\n","\n","            # 27 - 28\n","            'Isoelectric Point',\n","            'Secondary Structure Fraction' ]"]},{"cell_type":"markdown","metadata":{"id":"2ISd5y2jpSgV"},"source":["### Choose features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SYBeviRqpSgV"},"outputs":[],"source":["columns_to_find = columns[21:]\n","\n","feature_name = \"Full Physicochemical Properties\"\n","\n","indices = [dna_train.columns.get_loc(col) for col\n","           in columns_to_find if col in dna_train.columns]\n","\n","features = indices"]},{"cell_type":"markdown","metadata":{"id":"_7eTbXXepSgV"},"source":["### Create train_x, train_y, test_x, test_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"B_NZgw_JpSgV"},"outputs":[],"source":["train_x = dna_train.iloc[:, features]\n","test_x = dna_test.iloc[:, features]\n","train_y = dna_train.iloc[:, 0]\n","test_y = dna_test.iloc[:, 0]\n","\n","from imblearn.over_sampling import SMOTE\n","\n","smote = SMOTE(random_state=42)\n","train_x, train_y = smote.fit_resample(train_x, train_y)"]},{"cell_type":"markdown","metadata":{"id":"TOMjCrlypSgV"},"source":["# Model\n"]},{"cell_type":"markdown","metadata":{"id":"QwPxoF3MpSgY"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ONYvOFO7pSgZ"},"outputs":[],"source":["import seaborn as sns\n","import statsmodels.api as sm\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import matthews_corrcoef\n","from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_curve\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier, plot_tree\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from joblib import dump, load\n"]},{"cell_type":"markdown","metadata":{"id":"MnUIC7OypSgZ"},"source":["### Save models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-vaZ_j5JpSgZ"},"outputs":[],"source":["def save_model(model, name):\n","\n","    path = '/content/drive/MyDrive/IT1244 Group Project/For submission/Model & Data Set/' + name + '_Physicochemical_Properties.joblib'\n","\n","    # Saving the model\n","    dump(model, path)\n","\n","    # Loading the model\n","    loaded_model = load(path)"]},{"cell_type":"markdown","metadata":{"id":"Wn6fOzojpSgZ"},"source":["### Performance metrics - Set up"]},{"cell_type":"markdown","metadata":{"id":"6kenBLuRpSgZ"},"source":["##### Confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"S27WVoyNpSgZ"},"outputs":[],"source":["def sketch_confusion_matrix(test_set, predicted_set, name):\n","\n","    conf_matrix = confusion_matrix(test_set, predicted_set)\n","\n","    plt.figure(figsize=(15, 8))\n","\n","    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=['Non DNA-Binding', 'DNA-Binding'],\n","            yticklabels=['Non DNA-Binding', 'DNA-Binding'])\n","\n","    plt.title('Confusion Matrix of ' + name + \" - \" + feature_name)\n","\n","    plt.xlabel('Predicted Label')\n","\n","    plt.ylabel('True Label')\n","\n","    plt.show()\n","\n","    return conf_matrix"]},{"cell_type":"markdown","metadata":{"id":"Z8q46kYrpSgZ"},"source":["##### Performance metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7UyzvWNZpSgZ"},"outputs":[],"source":["\n","def get_performance_metrics(test, pred ,name):\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(test, pred)\n","    precision = precision_score(test, pred)\n","    recall = recall_score(test, pred)\n","    f1 = f1_score(test, pred)\n","    mcc = matthews_corrcoef(test, pred)\n","\n","    tn, fp, fn, tp = confusion_matrix(test, pred).ravel()\n","\n","    # Calculate sensitivity and specificitY\n","    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n","\n","    metrics = {\n","        \"Accuracy\": accuracy,\n","        \"Precision\": precision,\n","        \"Recall(Sensitivity)\": recall,\n","        \"F1 Score\": f1,\n","        \"Specificity\": specificity,\n","        \"MCC\": mcc\n","    }\n","\n","    print(\"Evaluation Metrics of \" + name + \" - \" + feature_name + \":\")\n","    print()\n","\n","    for key, value in metrics.items():\n","        print(f\"{key}: {value}\")\n","\n","    print()\n","    print()\n","    print(\"Classification Report of \" + name + \" - \" + feature_name + \":\")\n","    print()\n","    print(classification_report(test, pred))\n","\n","    return metrics\n"]},{"cell_type":"markdown","metadata":{"id":"UI54Z3eUpSgZ"},"source":["##### AUC - ROC"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4WWzIXzGpSgZ"},"outputs":[],"source":["def plot_roc_curve(y_test, y_probs, name):\n","\n","    # Step 5: Compute ROC curve and AUC\n","    fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n","    roc_auc = auc(fpr, tpr)\n","\n","    # Step 6: Plot ROC curve\n","    plt.figure(figsize=(15, 8))\n","    plt.plot(fpr, tpr, color='b', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n","    plt.xlabel('Specificity')\n","    plt.ylabel('Sensitivity')\n","    plt.title('ROC of '+ name + \" - \" + feature_name)\n","    plt.legend(loc=\"lower right\")\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"e2e9WmCGpSgZ"},"source":["##### AUC - PR"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"i9qp6qNSpSgZ"},"outputs":[],"source":["def plot_auc_pr(y_test, y_probs, name):\n","    # Step 1: Compute Precision-Recall curve\n","    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n","\n","    # Step 2: Compute AUC-PR\n","    auc_pr = auc(recall, precision)\n","\n","    # Step 3: Plot the Precision-Recall curve\n","    plt.figure(figsize=(15, 8))\n","    plt.plot(recall, precision, color='b', lw=2, label=f'PR curve (AUC = {auc_pr:.2f})')\n","    plt.xlabel('Sensitivity')\n","    plt.ylabel('Precision')\n","    plt.title('PR of ' + name + \" - \" + feature_name)\n","    plt.legend(loc=\"lower left\")\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"CqLQmV9rpSga"},"source":["### LOGISTIC REGRESSION"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fs7p3O4_pSga"},"outputs":[],"source":["\n","# Add a constant (intercept) to the model\n","train_x = sm.add_constant(train_x)\n","test_x = sm.add_constant(test_x)\n","\n","\n","# Fit logistic regression model\n","logit_model = sm.Logit(train_y, train_x)\n","result = logit_model.fit()\n","\n","\n","# Save model\n","# save_model(result, \"LR\")\n","\n","\n","# Print summary (which includes p-values)\n","print(result.summary())\n","\n","\n","# Predict probabilities and classes on the test set\n","predicted_probs = result.predict(test_x)\n","predicted_classes = np.where(predicted_probs >= 0.5, 1, 0)\n","\n","\n","# Confusion matrix\n","conf_matrix = sketch_confusion_matrix(test_y, predicted_classes,\n","                        \"Logistic Regression\")\n","\n","\n","# Performance metrics\n","print()\n","get_performance_metrics(test_y, predicted_classes, \"LOGISTIC REGRESSION\")\n","plot_roc_curve(test_y, predicted_probs, \"LOGISTIC REGRESSION\")\n","plot_auc_pr(test_y, predicted_probs, \"LOGISTIC REGRESSION\")\n"]},{"cell_type":"markdown","metadata":{"id":"L1J-ZeubpSga"},"source":["### K NEAREST NEIGHBOURS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n0WhbZ0QpSga"},"outputs":[],"source":["# Feature scaling\n","train_x_scaled = standardize(train_x)\n","test_x_scaled = standardize(test_x)\n","\n","\n","# Choose k value\n","\n","# mcc_list = []\n","\n","# for k in range(1, 267, 2):\n","#     knn = KNeighborsClassifier(n_neighbors=k)\n","#     knn.fit(train_x_scaled, train_y)\n","#     knn_pred = knn.predict(test_x_scaled)\n","#     mcc_list.append([k, matthews_corrcoef(test_y, knn_pred)])\n","\n","# print(max(mcc_list, key=lambda x: x[1]))\n","\n","\n","# Create the k-NN classifier with value k\n","k = 173\n","knn = KNeighborsClassifier(n_neighbors=k)\n","\n","\n","# Fit the model on the training data\n","knn.fit(train_x_scaled, train_y)\n","\n","\n","# Save model\n","# save_model(knn, \"KNN\")\n","\n","\n","# Make predictions on the test data\n","knn_pred = knn.predict(test_x_scaled)\n","knn_scores = knn.predict_proba(test_x_scaled)[:,1]\n","\n","\n","# Confusion matrix\n","conf_matrix = sketch_confusion_matrix(test_y, knn_pred, \"KNN with k = \" + str(k))\n","\n","\n","# Performance metrics\n","get_performance_metrics(test_y, knn_pred, \"KNN with k = \" + str(k))\n","plot_roc_curve(test_y, knn_scores, \"KNN with k = \" + str(k))\n","plot_auc_pr(test_y, knn_scores, \"KNN\")"]},{"cell_type":"markdown","metadata":{"id":"Sn4KPI72pSga"},"source":["### DECISION TREE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EOKC_1LnpSga"},"outputs":[],"source":["# Initialize and fit Decision Tree\n","dt_model = DecisionTreeClassifier(criterion='entropy', max_depth=7,\n","                                    min_samples_split=2, random_state=42)\n","dt_model.fit(train_x, train_y)\n","\n","\n","# Save model\n","# save_model(dt_model, \"DT\")\n","\n","\n","# Predict\n","dt_pred = dt_model.predict(test_x)\n","dt_scores = dt_model.predict_proba(test_x)[:,1]\n","\n","\n","# Visualize the Decision Tree\n","# plt.figure(figsize=(20,10))\n","# plot_tree(dt_model, filled=True, feature_names=train_x.columns,\n","#           class_names=[\"0\", \"1\"], rounded=True, fontsize=14)\n","# plt.title(\"Decision Tree - Physicochemical Properties\")\n","# plt.show()\n","\n","\n","# Confusion matrix\n","conf_matrix = sketch_confusion_matrix(test_y, dt_pred,\n","      \"Decision Tree\")\n","\n","\n","# Accuracy\n","get_performance_metrics(test_y, dt_pred, \"DECISION TREE\")\n","plot_roc_curve(test_y, dt_scores, \"DECISION TREE\")\n","plot_auc_pr(test_y, dt_scores, \"DECISION TREE\")"]},{"cell_type":"markdown","metadata":{"id":"y-jPa0OApSga"},"source":["### NAIVE BAYES"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yrb3f8BVpSga"},"outputs":[],"source":["# Initialize and fit Naive Bayes\n","nb_model = GaussianNB()\n","nb_model.fit(train_x, train_y)\n","\n","\n","# Save model\n","# save_model(nb_model, \"NB\")\n","\n","\n","# Predict\n","nb_pred = nb_model.predict(test_x)\n","nb_scores = nb_model.predict_proba(test_x)[:,1]\n","\n","\n","# Confusion matrix\n","conf_matrix = sketch_confusion_matrix(test_y, nb_pred,\n","      \"Naive Bayes - \" + feature_name + \":\")\n","\n","\n","# Performance metrics\n","get_performance_metrics(test_y, nb_pred, \"NAIVE BAYES\")\n","plot_roc_curve(test_y, nb_scores, \"NAIVE BAYES\")\n","plot_auc_pr(test_y, nb_scores, \"NAIVE BAYES\")"]},{"cell_type":"markdown","metadata":{"id":"6ZG5LFydpSgb"},"source":["### RANDOM FOREST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QFnui6zMpSgb"},"outputs":[],"source":["# Initialize and fit Random Forest\n","rf_model = RandomForestClassifier()\n","rf_model.fit(train_x, train_y)\n","\n","\n","# Save model\n","# save_model(rf_model, \"RF\")\n","\n","\n","# Performance metrics\n","rf_pred = rf_model.predict(test_x)\n","rf_scores = rf_model.predict_proba(test_x)[:,1]\n","\n","\n","# Confusion matrix\n","conf_matrix = sketch_confusion_matrix(test_y, rf_pred,\n","      \"Random Forest\")\n","\n","\n","# Performance metrics\n","get_performance_metrics(test_y, rf_pred, \"RANDOM FOREST\")\n","plot_roc_curve(test_y, rf_scores, \"RANDOM FOREST\")\n","plot_auc_pr(test_y, rf_scores, \"RANDOM FOREST\")"]},{"cell_type":"markdown","metadata":{"id":"DatfXvR_pSgb"},"source":["### SUPPORT VECTOR MACHINE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aV3vxOpFpSgb"},"outputs":[],"source":["# Feature scaling\n","train_x_scaled = standardize(train_x)\n","test_x_scaled = standardize(test_x)\n","\n","\n","# Initialize and fit SVM\n","svm_model = SVC(probability=True)\n","svm_model.fit(train_x_scaled, train_y)\n","\n","\n","# Save model\n","# save_model(svm_model, 'SVM')\n","\n","\n","# Predict\n","svm_pred = svm_model.predict(test_x_scaled)\n","svm_scores = svm_model.predict_proba(test_x_scaled)[:,1]\n","\n","\n","# Confusion matrix\n","conf_matrix = sketch_confusion_matrix(test_y, svm_pred,\n","      \"Support Vector Machine\")\n","\n","\n","# Performance metrics\n","print(get_performance_metrics(test_y, svm_pred, \"SUPPORT VECTOR MACHINE\"))\n","plot_roc_curve(test_y, svm_scores, \"SUPPORT VECTOR MACHINE\")\n","plot_auc_pr(test_y, svm_scores, \"SUPPORT VECTOR MACHINE\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}